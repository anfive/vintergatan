/** simulation.cpp
Author: Andrea Ferrario

Implementation of the simulation algorithm.

*/

#include <memory>
#include <iostream>
#include <thread>
#include <algorithm>
#define _USE_MATH_DEFINES
#include <math.h>
#include <cassert>

#include "simulation.h"
#include "octree.h"
#include "omp.h"

/** Implementation of the simulation algorithm.
This struct contains:
- The configuration for the simulation and pointers to the shared data,
- The state of the simulation,
- Data structures such as the Barnes-Hut tree and the particle-to-thread assignments,
- Timing utilities.

The simulation algorithm is run in a loop in the run() method. Each loop iteration
computes a time step. Each time step is made up of a number of passes:
- Pass 1: run serially on the master thread. Consists of three operations:
- Sort particles:     the particles are sorted according to their Morton index (that identifies
their position in space).
- Detect collisions:  particles close enough to have the same Morton index	are treated as collided, since they
cannot be represented in the Barnes-Hut octree. One particle is inactivated (removed from
the simulation) while the second is updated to simulate a particle generated by an
inelastic collision (the mass is the sum of the masses, the momentum is conserved).
- Load distributions: particles are distributed to different threads for the force computation steps, according to
each particle's estimated computational cost. The cost is estimated from the number of force
calculations required by the particle in the previous time step.
- Pass 2: create the Barnes-Hut octree. The particles are split equally among all threads and added to the tree data
structures according to their Morton indices. The properties of the tree nodes (center of mass, etc.) are
computed
- Pass 3: force calculation. The force (or rather, the acceleration and its time derivative) acting on each particle
is computed using the Barnes-Hut octrees. Contributions to the force by particles that are close to the
target particle are added directly, while the contributions of particles far away are added by grouping
them using the tree structure. This pass is the most expensive computationally, since it scales like n*log(n).
- Pass 4: time integration. Using the computed forces, integrate the equation of motion using a 4th order Hermite integrator.
update the rendering data used for visualization

The Hermite integrator actually uses a Predict-Evaluate-Correct scheme, that is implemented as follows:
- During Pass 4, the integrator computes the Predicted position and velocity of each particle.
- During Pass 3 of the following loop iteration, the predicted values are used to compute the force.
- During the next Pass 4, the integrator corrects the predicted values using the computed force.

*/
struct SimulationImpl {

  /** Struct representing a range of particles (indices from begin to end),
  used to distribute subsets of the particles to each thread.
  The struct is cache-aligned.
  */
  struct alignas(64) ParticleRange {
    /** Begin of the particle indices range. */
    unsigned int begin;
    /** End of the particle indices range. */
    unsigned int end;
    ParticleRange() : begin(0), end(0) {}
  };

  /* Configuration data */

  /** Number of simulation threads. */
  const unsigned int threadCount;
  /** Number of particles. */
  const unsigned int particleCount;
  /** Pointer to the rendering data array, shared with the graphics.
  This array is updated at each time step with the computed particle positions. */
  float* const renderingData;
  /** Pointer to the particle data, containing (most of) the state of the simulation. */
  Particle* const particleData;
  /** Constant value of the time step. */
  const double deltaT;

  /** Struct containing additional state information. */
  struct {
    /** True if the simulation is running.
    This flag is set to false asynchronously to stop the simulation. */
    bool running;
    /** Total computational cost of the last computed time step.
    This cost is the total number of force calculations between particles. */
    size_t computationalCost;

    /* Acceleration and Jerk */
    // These arrays contains accelerations and jerks (first derivative of the acceleration)
    // for the last computed time step and the ones to be used in computing the next step.
    // They are kept as separate pointers to the arrays to allow swapping the "last step" ones
    // with the "next step" ones with just a pointer swap, saving an unnecessary copy operation.

    /** Values of the acceleration at the last computed time step for all particles. */
    std::unique_ptr<Vector3[]> accelerations;
    /** Values of the jerks (time derivative of the acceleration) at the last computed time step for all particles. */
    std::unique_ptr<Vector3[]> jerks;
    /** Values of the acceleration to be used when computing the next time step for all particles. */
    std::unique_ptr<Vector3[]> accelerations1;
    /** Values of the jerks (time derivative of the acceleration) to be used when computing the next time step for all particles. */
    std::unique_ptr<Vector3[]> jerks1;

  } state;

  // Types used to measure performance

  using TimePoint = std::chrono::high_resolution_clock::time_point;
  using Duration = std::chrono::high_resolution_clock::duration;

  /** Struct containing timers and intervals used to measure the performance of the
  different parts of the algorithm and to limit the time stepping rate. */
  struct {

    /** Time point of the last performance measurement. */
    TimePoint countBegin;


    /** Time point used to measure time intervals. */
    TimePoint timer;

    /** Time spent in each pass of the simulation at the last time step. */
    Duration particleSorting, octreeConstruction, forceCalculation, timeIntegration;

    /** If the time stepping rate (time steps to compute per second) has been specified,
    this contains the minimum duration of a time step computation. */
    Duration minTimeStepDuration = Duration::zero();

    /** If the time stepping rate (time steps to compute per second) has been specified,
    this contains the time point at which this simulation step should end.
    The simulation will wait until this time to proceed with the next step. */
    TimePoint timeStepEnd;

    /** Resets all the measuring timers to zero. */
    void reset() {
      particleSorting = Duration::zero();
      octreeConstruction = Duration::zero();
      forceCalculation = Duration::zero();
      timeIntegration = Duration::zero();
    }

  } timing;

  /** Barnes-Hut octrees, one per thread.
  Octree classes are cache-aligned to avoid false sharing. */
  std::vector<Octree> octrees;

  /** Distribution of particles per thread according to their computational cost.
  The particles are distributed so that each thread has a similar amount of computational cost
  (computed as the total number of force calculations) estimated from the last time step.
  This distribution is used for balancing the load during force calculations. */
  std::vector<ParticleRange> loadBalancedParticles;

  /** Vector used to sort particles in order of their Morton indices.
  The first element of the pair is the particle's index in the particleData array. */
  std::vector<std::pair<unsigned int, Particle*>> particlesByMortonIndex;

  /** Constructor. */
  SimulationImpl(const unsigned int threadCount,
    float * const renderingData,
    Particle* const particleData,
    const unsigned int particleCount,
    const double deltaT,
    const unsigned int timeStepLimit);

  /** Run method.
  Runs the simulation with the specified number of threads,
  blocking until the SimulationImpl::state::running flag is set to false.
  */
  void run();

  /** Pass 1: sort particles, detect collisions, and distribute the load.
  This pass is run on the master thread and is the only part not parallelized.
  */
  void sortParticles();

  /** Pass 2: create octree.
  Each thread will process the assigned range of particle in the vector of particles
  sorted by their Morton index, adding them to their local octree.
  */
  void createOctree(const unsigned int threadId, Octree& octree, const ParticleRange& range);

  /** Pass 3: compute forces
  Using the predicted position and velocity from the previous loop, compute the accelerations and jerks acting on
  each particle in the range. The range used here is load balanced according to each particle's computational weight
  in the previous step.
  */
  void computeForce(const unsigned int threadId, const ParticleRange& range);

  /** Method used during Pass 3. Adds all the force contributions from the given octree to the specified vectors a (acceleration)
  and adot (jerk), using the predicted values of position and velocity for the particle. Increments the forceCalc counter.*/
  void addForceContributions(const Octree & octree, const unsigned int particleId, Particle & p, Vector3& a, Vector3& adot, unsigned int & forceCalcs) const;

  /** Pass 4: perform time integration.
  From the values at the previous step and the computed accelerations and jerks, performs a correction of the predicted positions and velocities,
  computing the positions and velocities of all particles at this time step.
  At the same time, computes the predicted position and velocities for the next step (to be used in computeForce in the next loop)
  and copies the positions to the rendering data array.
  */
  void doTimeIntegration(const unsigned int threadId, const ParticleRange& range);

};

void SimulationImpl::sortParticles() {

  // This pass is run on the master thread only.
#pragma omp master
  {
    timing.timer = std::chrono::high_resolution_clock::now();

    /* Sort Particles. */
    // Sort particles according to their Morton index after they have been moved during time integration.
    // Due to the space locality properties of Morton indices, the vector is mostly sorted already, so re-sorting should be typically fast.
    std::sort(particlesByMortonIndex.begin(), particlesByMortonIndex.end(),
      [](std::pair<unsigned int, const Particle*> p0, std::pair<unsigned int, const Particle*> p1) { return p0.second->index < p1.second->index;  });

    /* Detect collisions between particles. */
    // Particles collide when they cannot be placed in two different Barnes-Hut octree nodes at the finest level,
    // i.e. when their Morton index is the same.
    // Using the vector just sorted, this operation can be done by looping through the vector once, by comparing 
    // each particle with the previous (active) one.

    unsigned int previousId = 0;
    Particle* previous = nullptr;
    unsigned int collisions = 0;

    for (unsigned int i = 0; i < particleCount; ++i) {

      Particle& particle2 = *particlesByMortonIndex[i].second;
      if (!particle2.active) {
        // Skip inactive particles.
        continue;
      }
      const auto ix2 = particlesByMortonIndex[i].first;

      if (!previous) {
        // This is the first active particle. Proceed with the next one.
        previousId = i;
        previous = &particle2;
        continue;
      }

      Particle& particle1 = *previous;
      const auto ix1 = particlesByMortonIndex[previousId].first;

      if (particle1.index == particle2.index) {
        // The particles collided.
        // One particle is marked as inactive and will not be included in the simulation anymore.
        // The other particle will be used for the result of the inelastic collision:
        // the new mass will be the sum of the mass, the new position will be the position of the center of mass,
        // and the new velocity is computed using conservation of momentum.

        const double totalMass = particle1.mass + particle2.mass;

        particle1.vel = (particle1.vel * particle1.mass + particle2.vel * particle2.mass) / totalMass;
        particle1.pos = (particle1.pos * particle1.mass + particle2.pos * particle2.mass) / totalMass;
        particle1.mass = totalMass;

        particle2.mass = NAN;
        particle2.pos = Vector3(NAN, NAN, NAN);
        particle2.vel = Vector3(NAN, NAN, NAN);
        particle2.active = false;

        // The particle2 is inactive, so its rendeing data will not be updated anymore.
        // Set it to nans.
        renderingData[3 * ix2] = NAN;
        renderingData[3 * ix2 + 1] = NAN;
        renderingData[3 * ix2 + 2] = NAN;

        ++collisions;
      }
      else {

        // No collision. Proceed with the next particle.
        previousId = i;
        previous = &particle2;
      }
    }

    if (collisions > 0) {
      //std::cout << collisions << " particle collisions in the last time step." << std::endl;
    }

    /* Load Balancing */
    // Divide the active particles among threads so that each thread will get more or less
    // the same computational work. The work for a particle is estimated with the number of force calculation
    // that the particle received in the previous time step.

    unsigned int currentThread = 0;
    // Accumulated total cost for the current thread.
    size_t currentCost = 0;
    // Target cost for each thread.
    const size_t targetCostPerThread = state.computationalCost / threadCount;
    // The first thread's range starts at zero.
    loadBalancedParticles[0].begin = 0;
    unsigned int i = 0;
    for (; i < particleCount; ++i) {
      Particle& particle = particleData[i];
      if (!particle.active) {
        // Skip inactive particles.
        continue;
      }

      if (currentCost + particle.computationalWeight > targetCostPerThread) {
        // Adding this particle would exceed the target cost.
        // Assign it to the next thread.
        loadBalancedParticles[currentThread].end = i;
        ++currentThread;
        loadBalancedParticles[currentThread].begin = i;
        if (currentThread == threadCount - 1) {
          // No need to iterate on the particles for the last thread:
          // it will get all the remaining particles.
          break;
        }
        currentCost = 0;
      }

      currentCost += particle.computationalWeight;
      // Reset the computational cost for this particle for the next step.
      particle.computationalWeight = 0;
    }
    // Finish resetting the computational cost for the particles.
    for (; i < particleCount; ++i) {
      Particle& particle = particleData[i];
      if (particle.active) {
        particle.computationalWeight = 0;
      }
    }
    // The last thread gets all the remaining particles.
    loadBalancedParticles[currentThread].end = particleCount;

    // If there are additional threads, assign zero particles to them
    // (this happens only if threadCount > particleCount).
    for (++currentThread; currentThread < threadCount; ++currentThread) {
      loadBalancedParticles[currentThread].begin = particleCount;
      loadBalancedParticles[currentThread].end = particleCount;
    }

    // Reset the computational cost for the time step.
    state.computationalCost = 0;

    timing.particleSorting += (std::chrono::high_resolution_clock::now() - timing.timer);
    timing.timer = std::chrono::high_resolution_clock::now();

  }

}

void SimulationImpl::createOctree(const unsigned int threadId, Octree& localOctree, const ParticleRange& range) {

  // Create local octree
  localOctree.clear();

  // Add all the particles in the range in order of their Morton index.
  for (unsigned int i = range.begin; i < range.end; ++i) {
    Particle& p = *particlesByMortonIndex[i].second;
    if (p.active) {
      localOctree.addParticle(&p);
    }
  }

  // Compute centers of mass for each node.
  localOctree.computeCOMs();

}

void SimulationImpl::computeForce(const unsigned int threadId, const ParticleRange& range) {

  // Count the total number of force calculations to estimate the 
  // computational cost of the next step.
  unsigned int forceCalcs = 0;

  // Iterate on all octrees and add their contributions to the accelerations and jerks 
  // of all particles in the assigned range.
  for (const auto& octree : octrees) {
    for (unsigned int i = range.begin; i < range.end; ++i) {

      Particle& p = particleData[i];
      if (!p.active) {
        // Skip inactive particles.
        continue;
      }

      Vector3& a = state.accelerations1[i];
      Vector3& adot = state.jerks1[i];

      addForceContributions(octree, i, p, a, adot, forceCalcs);
    }
  }

  // Collect the total computational cost from all threads.
#pragma omp atomic
  state.computationalCost += forceCalcs;

}

void SimulationImpl::addForceContributions(const Octree& octree, const unsigned int particleId, Particle& p, Vector3& a, Vector3& adot, unsigned int& forceCalcs) const {

  size_t i = 0;

  // Create an OctreeIterator object to iterate on the octree.
  OctreeIterator iterator(octree);

  const OctreeNode* node = iterator.getNextNode();

  while (node) {
    const Vector3 r = node->centerOfMass - p.predictedPos;

    // Compute the distance between the particle and the node's center of mass.
    double distanceSq = r.absSq();

    // Determine whether to use this node for the force calculation, or if
    // it necessary to investigate its children.
    if (node->particle || distanceSq > node->openingThreshold) {

      // Do not add contribution of a particle to itself.
      if (!node->particle || node->particle != &p) {

        // Compute the distance to use in the acceleration expression.
        // Use a "softening distance" to mitigate the divergence of the force at
        // very close distances.
        distanceSq += SOFTENING_DISTANCE * SOFTENING_DISTANCE;
        const double distance = sqrt(distanceSq);

        const Vector3 relativeVelocity = node->centerOfMassVelocity - p.predictedVel;

        // NOTE: The multiplication by the constant G is not done here, to save one floating point multiplication
        // per force calculation. It is done once per particle in the force calculation pass.
        // Add the contribution to the acceleration: m*r/abs(r)^3
        a = a + (r * (node->mass / (distanceSq * distance)));
        // Add the contribution to the jerk: m * (rv * abs(r)^2) - 3 * r * dot(r, rv)) / abs(r)^5
        adot = adot + (relativeVelocity * distanceSq - r * 3.0 * r.dot(relativeVelocity)) * node->mass / (distanceSq * distanceSq * distance);

        // Increase counters:
        // Total number of force calculations
        ++forceCalcs;
        // Number of force calculation for this particle.
        ++p.computationalWeight;
      }

      // We used this node for the contribution, so don't proceed with the children,
      // go straight to the sibling node.
      node = iterator.getSiblingNode();

    }
    else {

      // Proceed with the children of this node.
      node = iterator.getNextNode();

    }
  }

}

void SimulationImpl::doTimeIntegration(const unsigned int threadId, const ParticleRange& range) {

  for (unsigned int i = range.begin; i < range.end; ++i) {

    auto& particle = particleData[i];

    if (!particle.active) {
      // Skip inactive particles
      continue;
    }

    Vector3& p0 = particle.pos; // Position of the particle at the last time step.
    Vector3& v0 = particle.vel; // Velocity of the particle at the last time step.
    Vector3& rp = particle.predictedPos; // Position of the particle at this time step, predicted from last step's values.
    Vector3& vp = particle.predictedVel; // Velocity of the particle at this time step, predicted from last step's values.
    Vector3& a0 = state.accelerations[i]; // Acceleration of the particle at the last time step.
    Vector3& a1 = state.accelerations1[i]; // Acceleration of the particle at this time step, computed from the predicted rp and vp.
    Vector3& adot0 = state.jerks[i]; // Jerk of the particle at the last time step.
    Vector3& adot1 = state.jerks1[i]; // Jerk of the particle at this time step, computed from the predicted rp and vp.

                                      // Multiply the computed accelerations and jerks by G.
                                      // This is not done during force calculation to avoid additional unnecessary
                                      // floating point multiplications.
    a1 = a1 * G;
    adot1 = adot1 * G;

    // Integrate equation of motion (Hermite predictor-estimator-corrector)

    // Perform correction from the last step's values, computing the new position and velocity.

    v0 = v0 + ((a1 + a0) + (adot0 - adot1) * deltaT * (1.0 / 6.0)) * (deltaT * 0.5);
    p0 = p0 + ((vp + v0) + (a0 - a1) * deltaT * (1.0 / 6.0)) * (deltaT * 0.5);

    // Perform prediction of position and velocity for the next step:

    // rp = p0 + v0*dt + 1/2*a*dt^2 + 1/6*adot*dt^3
    rp = p0 + (v0 + (a1 * 0.5 + adot1 * (1.0 / 6.0) * deltaT) * deltaT) * deltaT;
    // vp = v0 + a0*dt + 1/2*adot*dt^2
    vp = v0 + (a1 + adot1 * 0.5 * deltaT) * deltaT;

    // Check if the predicted position is outside the simulation area.
    if (rp.x > BOX_SIZE / 2.0 || rp.x < -BOX_SIZE / 2.0
      || rp.y > BOX_SIZE / 2.0 || rp.y < -BOX_SIZE / 2.0
      || rp.z > BOX_SIZE / 2.0 || rp.z < -BOX_SIZE / 2.0) {
      // Mark the particle as inactive.
      p0 = Vector3(NAN, NAN, NAN);
      v0 = Vector3(NAN, NAN, NAN);
      particle.active = false;
      particle.mass = 0.0;
    }

    // Update rendering data for the particle.
    renderingData[i * 3] = static_cast<float>(p0.x);
    renderingData[i * 3 + 1] = static_cast<float>(p0.y);
    renderingData[i * 3 + 2] = static_cast<float>(p0.z);

    // Reset acceleration and jerk and recompute the Morton index.
    a0 = 0;
    adot0 = 0;
    particle.index = MortonIndex(p0);

  }

}

void SimulationImpl::run() {

  state.running = true;

  timing.reset();
  timing.countBegin = std::chrono::high_resolution_clock::now();

  size_t frames = 0;

  // Begin parallel section.
#pragma omp parallel num_threads(threadCount)
  {

    const unsigned int threadId = omp_get_thread_num();

#pragma omp critical
    {
      std::cout << "Simulation thread " << threadId << " starting" << std::endl;
    }

    // Divide the particles equally among threads.
    // This division is used for those passes in which the work done for each particle is about the same.
    ParticleRange range;
    {
      const unsigned int particlesPerThread = particleCount / threadCount;
      range.begin = threadId * particlesPerThread;
      range.end = (threadId != threadCount - 1) ? (threadId + 1) * particlesPerThread : particleCount;
    }

    Octree& localOctree = octrees[threadId];

    // Main Loop
    while (state.running) {

      // Pass 1
      sortParticles();

#pragma omp barrier

      // Pass 2
      createOctree(threadId, localOctree, range);

#pragma omp barrier

#pragma omp master
      {
        timing.octreeConstruction += (std::chrono::high_resolution_clock::now() - timing.timer);
        timing.timer = std::chrono::high_resolution_clock::now();
      }
      //  Pass 3
      computeForce(threadId, loadBalancedParticles[threadId]);

#pragma omp barrier

#pragma omp master
      {
        timing.forceCalculation += (std::chrono::high_resolution_clock::now() - timing.timer);
        timing.timer = std::chrono::high_resolution_clock::now();
      }
      // Pass 4
      doTimeIntegration(threadId, range);

#pragma omp barrier

      // Finalization
#pragma omp master
      {
        // Swap the acceleration and jerks of the current step with the ones for the previous step, 
        // so that they can be used as previous step in the next loop.
        state.accelerations.swap(state.accelerations1);
        state.jerks.swap(state.jerks1);

        timing.timeIntegration += (std::chrono::high_resolution_clock::now() - timing.timer);

        // If a limit to the time stepping rate has been imposed, wait until the prescribed time.
        std::this_thread::sleep_until(timing.timeStepEnd);

        ++frames;

        // Periodically write performance information to the console.
        const auto now = std::chrono::high_resolution_clock::now();
        if (now > timing.countBegin + PERFORMANCE_LOGGING_INTERVAL) {

          const auto us = std::chrono::duration_cast<std::chrono::nanoseconds>(now - timing.countBegin).count();
          const double tsps = 1.0e9 * frames / us;

          std::cout << "Time steps per second: " << tsps << ", Force calculations per step: " << state.computationalCost << std::endl
            << " Sorting: " << timing.particleSorting.count() / frames
            << " ns, Octree: " << timing.octreeConstruction.count() / frames
            << " ns, Forces: " << timing.forceCalculation.count() / frames
            << " ns, Integr: " << timing.timeIntegration.count() / frames << " ns" << std::endl;

          frames = 0;
          timing.reset();
          timing.countBegin = now;

        }

        timing.timeStepEnd = std::chrono::high_resolution_clock::now() + timing.minTimeStepDuration;

      }

#pragma omp barrier

    } // End of main loop.

#pragma omp critical
    {
      std::cout << "Simulation thread " << threadId << " stopping" << std::endl;
    }

  } // End of parallel region.

}



SimulationImpl::SimulationImpl(const unsigned int threadCount, float* const renderingData, Particle* const particleData, const unsigned int particleCount, const double deltaT, const unsigned int timeStepLimit)
  : threadCount(threadCount), renderingData(renderingData), particleData(particleData), deltaT(deltaT), particleCount(particleCount) {
  assert(renderingData);
  assert(particleData);
  assert(particleCount > 0);
  assert(threadCount > 0);
  assert(deltaT > 0.0);

  std::cout << "Initializing simulation with " << particleCount << " particles." << std::endl;

  // Create state data
  state.accelerations.reset(new Vector3[particleCount]);
  state.jerks.reset(new Vector3[particleCount]);
  state.accelerations1.reset(new Vector3[particleCount]);
  state.jerks1.reset(new Vector3[particleCount]);

  // Initialize particle data and state

  particlesByMortonIndex.resize(particleCount);
  for (unsigned int i = 0; i < particleCount; ++i) {
    particleData[i].index = MortonIndex(particleData[i].pos);
    particleData[i].predictedPos = particleData[i].pos;
    particleData[i].predictedVel = particleData[i].vel;
    particlesByMortonIndex[i] = std::make_pair(i, &particleData[i]);
  }

  // At the beginning, there is no information on the computational cost.
  // so each particle is assumed to have computational cost of 1.
  state.computationalCost = particleCount;

  // Other initializations

  octrees.resize(threadCount);
  loadBalancedParticles.resize(threadCount);
  if (timeStepLimit == 0) {
    timing.minTimeStepDuration = Duration::zero();
  }
  else {
    timing.minTimeStepDuration = std::chrono::nanoseconds(1000000000) / timeStepLimit;
    std::cout << "Time stepping limited to " << timeStepLimit << " time steps per second." << std::endl;
  }

}

Simulation::Simulation(const unsigned int threadCount, float* const renderingData, Particle* const particleData, const unsigned int particleCount, const double deltaT, const unsigned int timeStepLimit)
  : impl(new SimulationImpl(threadCount, renderingData, particleData, particleCount, deltaT, timeStepLimit)) {
}

Simulation::~Simulation() {
}

void Simulation::runParallel() {
  impl->run();
}

void Simulation::stop() {
  impl->state.running = false;
}
